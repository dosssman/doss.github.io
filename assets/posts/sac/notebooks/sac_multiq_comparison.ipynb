{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deps\n",
    "import os\n",
    "import os.path as path\n",
    "\n",
    "import wandb\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting related\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"darkgrid\") # Styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration:\n",
    "## Set the WANDB entity and project name to be used\n",
    "wandb_entity_project = \"dosssman/drlforge-multiq\"\n",
    "\n",
    "# Cache dir structure\n",
    "cache_dir = wandb_entity_project.replace(\"/\",\"_\").replace(\"-\", \"_\").replace(\".\",\"_\") # Make it simple folder name\n",
    "cache_dir += \"n_q_comparison\"\n",
    "\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "\n",
    "# Episode reward cached data\n",
    "all_env_cache_filename = os.path.join( cache_dir, \"all_envs.pkl\")\n",
    "all_df_cache_filename = os.path.join( cache_dir, \"all_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Info: No cache found. Downloading data ...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['eval/train_episode_return']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-84e30ee160e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"total_steps\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_dataframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval/train_episode_return\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval/train_episode_return\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval/train_episode_return\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrolling_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrolling_average\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drl-forge/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdropna\u001b[0;34m(self, axis, how, thresh, subset, inplace)\u001b[0m\n\u001b[1;32m   4746\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4747\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4748\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4749\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ['eval/train_episode_return']"
     ]
    }
   ],
   "source": [
    "# DDPG: Data loading for Train Episode Return Plots.\n",
    "api = wandb.Api()\n",
    "\n",
    "runs = api.runs(wandb_entity_project)\n",
    "summary_list = [] \n",
    "config_list = [] \n",
    "name_list = []\n",
    "envs = {}\n",
    "data = []\n",
    "rolling_average = 10\n",
    "sample_points = 500\n",
    "\n",
    "if not path.exists(all_env_cache_filename) or not path.exists(all_df_cache_filename):\n",
    "    print( \"# Info: No cache found. Downloading data ...\")\n",
    "    # Loading full data in case no cached is found\n",
    "    for idx, run in enumerate(runs):\n",
    "        ls = run.history(keys=['eval/train_episode_return', 'global_step'], pandas=False)\n",
    "        metrics_dataframe = pd.DataFrame(ls[0])\n",
    "        metrics_dataframe.insert(len(metrics_dataframe.columns), \"algo\", run.config['exp_name'])\n",
    "        metrics_dataframe.insert(len(metrics_dataframe.columns), \"seed\", run.config['seed'])\n",
    "        data += [metrics_dataframe]\n",
    "        if run.config[\"env_id\"] not in envs:\n",
    "            envs[run.config[\"env_id\"]] = [metrics_dataframe]\n",
    "            envs[run.config[\"env_id\"]+\"total_steps\"] = run.config[\"total_steps\"]\n",
    "        else:\n",
    "            envs[run.config[\"env_id\"]] += [metrics_dataframe]\n",
    "\n",
    "        # run.summary are the output key/values like accuracy.  We call ._json_dict to omit large files \n",
    "        summary_list.append(run.summary._json_dict) \n",
    "\n",
    "        # run.config is the input metrics.  We remove special values that start with _.\n",
    "        config_list.append({k:v for k,v in run.config.items() if not k.startswith('_')}) \n",
    "\n",
    "        # run.name is the name of the run.\n",
    "        name_list.append(run.name)       \n",
    "\n",
    "    summary_df = pd.DataFrame.from_records(summary_list)\n",
    "    config_df = pd.DataFrame.from_records(config_list) \n",
    "    name_df = pd.DataFrame({'name': name_list}) \n",
    "    all_df = pd.concat([name_df, config_df,summary_df], axis=1)\n",
    "    data = pd.concat(data, ignore_index=True)\n",
    "    \n",
    "    # Smoothing\n",
    "    rolling_average = 20\n",
    "    for env in envs:\n",
    "        if not env.endswith(\"total_steps\"):\n",
    "            for idx, metrics_dataframe in enumerate(envs[env]):\n",
    "                envs[env][idx] = metrics_dataframe.dropna(subset=[\"eval/train_episode_return\"])\n",
    "                envs[env][idx][\"eval/train_episode_return\"] = metrics_dataframe[\"eval/train_episode_return\"].rolling(rolling_average).mean()[rolling_average:]\n",
    "    \n",
    "    with open(all_df_cache_filename, 'wb') as handle:\n",
    "        pickle.dump(all_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(all_env_cache_filename, 'wb') as handle:\n",
    "        pickle.dump(envs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print( \"# Info: Data loaded and cached.\")\n",
    "else:\n",
    "    with open(all_df_cache_filename, 'rb') as handle:\n",
    "        all_df = pickle.load(handle)\n",
    "    with open(all_env_cache_filename, 'rb') as handle:\n",
    "        envs = pickle.load(handle)\n",
    "    print( \"# Info: Data loaded from cache.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Get Dataframe of the Episode reward given the environment\n",
    "# TODO: Implement caching\n",
    "def get_df_for_env(env_id):\n",
    "    env_total_steps = envs[env_id+\"total_steps\"]\n",
    "    env_increment = env_total_steps / 500\n",
    "    envs_same_x_axis = []\n",
    "    for sampled_run in envs[env_id]:\n",
    "        df = pd.DataFrame(columns=sampled_run.columns)\n",
    "        x_axis = [i*env_increment for i in range(500-2)]\n",
    "        current_row = 0\n",
    "        for timestep in x_axis:\n",
    "            while sampled_run.iloc[current_row][\"global_step\"] < timestep:\n",
    "                current_row += 1\n",
    "                if current_row > len(sampled_run)-2:\n",
    "                    break\n",
    "            if current_row > len(sampled_run)-2:\n",
    "                break\n",
    "            temp_row = sampled_run.iloc[current_row].copy()\n",
    "            temp_row[\"global_step\"] = timestep\n",
    "            df = df.append(temp_row)\n",
    "        \n",
    "        envs_same_x_axis += [df]\n",
    "    return pd.concat(envs_same_x_axis, ignore_index=True)\\\n",
    "\n",
    "# Caching data for all environments all at once\n",
    "ALL_ENVS = list(sorted(set(all_df[\"env_id\"])))\n",
    "ALL_ENV_EPISODE_RETURN_DF = {}\n",
    "\n",
    "ep_return_cachedir = os.path.join( cache_dir, \"episode_return\")\n",
    "if not path.exists( ep_return_cachedir):\n",
    "    os.makedirs(ep_return_cachedir)\n",
    "\n",
    "for env_name in ALL_ENVS:\n",
    "    print( f\"# INFO: Fetching / Loading data for {env_name}\")\n",
    "    \n",
    "    env_ep_return_cachefile = os.path.join( ep_return_cachedir, f\"{env_name}_cache.pkl\")\n",
    "    if not path.exists(env_ep_return_cachefile):\n",
    "        print(\"#  Cached data not found, reading runs data from WANDB\")\n",
    "        # Actually process the data. Takes most of the time.\n",
    "        env_df = get_df_for_env(env_name)\n",
    "        \n",
    "        with open(env_ep_return_cachefile, 'wb') as handle:\n",
    "            pickle.dump(env_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        # Load it from cached data\n",
    "        print(\"#  Cached data found and loaded\")\n",
    "        with open(env_ep_return_cachefile, 'rb') as handle:\n",
    "            env_df = pickle.load(handle)\n",
    "    \n",
    "    # Add the data to global variable for later usage\n",
    "    ALL_ENV_EPISODE_RETURN_DF[f\"{env_name}\"] = env_df\n",
    "\n",
    "print( \"# INFO: All data loading done for episode reward data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for one environment\n",
    "env_name = \"Hopper-v2\"\n",
    "\n",
    "# Get the dataframe\n",
    "env_df = ALL_ENV_EPISODE_RETURN_DF[env_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(env_df[\"algo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_readable = {\n",
    "    \"sac_multiq_1\": \"SAC 1Q\",\n",
    "    \"sac_multiq_2\": \"SAC 2Q\",\n",
    "    \"sac_multiq_3\": \"SAC 3Q\",\n",
    "    \"sac_multiq_4\": \"SAC 4Q\",\n",
    "    \"sac_multiq_5\": \"SAC 5Q\",\n",
    "    \"sac_multiq_8\": \"SAC 8Q\",\n",
    "    \"sac_multiq_10\": \"SAC 10Q\",\n",
    "    \"sac_multiq_12\": \"SAC 12Q\",\n",
    "    \"sac_multiq_20\": \"SAC 20Q\",\n",
    "}\n",
    "\n",
    "exp_names = [\"sac_multiq_1\", \"sac_multiq_2\", \"sac_multiq_3\", \"sac_multiq_4\", \"sac_multiq_5\", \"sac_multiq_8\",\n",
    "             \"sac_multiq_10\", \"sac_multiq_12\", \"sac_multiq_20\"]\n",
    "current_palette = sns.color_palette(n_colors=len(exp_names)) # TODO: Change palette to match the WANDB logs ?\n",
    "# current_palette[0] = \"teal\"\n",
    "# current_palette = np.array([\n",
    "#     [240,184,153],\n",
    "#     [34,148,135],\n",
    "#     [83,135,221]\n",
    "# ]) / 255.\n",
    "current_palette_dict = dict(zip(exp_names, current_palette))\n",
    "# current_palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameterization\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# Plot the data onto the ax object\n",
    "sns.lineplot(data=env_df,\n",
    "    x=\"global_step\",\n",
    "    y=\"eval/train_episode_return\",\n",
    "    ci='sd', ax=ax, hue=\"algo\",\n",
    "    palette=current_palette_dict\n",
    ")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "leg = ax.legend(handles=handles[1:], labels=labels[1:])\n",
    "labels = [label_to_readable[label] for label in labels[1:]]\n",
    "    \n",
    "# Plot config and pretify\n",
    "ax.set_title(env_name)\n",
    "ax.set_xlabel(\"Time steps\")\n",
    "ax.set_ylabel(\"Episode return\")\n",
    "ax.ticklabel_format(style='sci', scilimits=(0,0), axis='x')\n",
    "ax.legend(handles[1:], labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates plots for all the environments\n",
    "for env_name in ALL_ENVS:\n",
    "    env_df = env_df = ALL_ENV_EPISODE_RETURN_DF[env_name]\n",
    "    \n",
    "    # Plot parameterization\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "    # Plot the data onto the ax object\n",
    "    sns.lineplot(data=env_df,\n",
    "        x=\"global_step\",\n",
    "        y=\"eval/train_episode_return\",\n",
    "        ci='sd', ax=ax, hue=\"algo\",\n",
    "        palette=current_palette_dict\n",
    "    )\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    leg = ax.legend(handles=handles[1:], labels=labels[1:])\n",
    "    labels = [label_to_readable[label] for label in labels[1:]]\n",
    "\n",
    "    # Plot config and pretify\n",
    "    ax.set_title(env_name)\n",
    "    ax.set_xlabel(\"Time steps\")\n",
    "    ax.set_ylabel(\"Episode return\")\n",
    "    ax.ticklabel_format(style='sci', scilimits=(0,0), axis='x')\n",
    "    ax.legend(handles[1:], labels)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "#     fig.savefig(f\"{env_name}_EpisodeReturn_NoiseType.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
